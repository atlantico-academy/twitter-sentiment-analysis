{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bb5df34-8a87-415f-85cf-97fdf4756c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/joseaurelio/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# importando bibliotecas \n",
    "from pathlib import Path\n",
    "from IPython.display import Markdown\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import nltk\n",
    "\n",
    "# importando stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aab5306d-a741-47d9-b3e4-f1b81596a6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregamento conjunto de dados\n",
    "data_path = Path(\"../data/raw/data.csv\")\n",
    "\n",
    "# carregamento dicionário de dados\n",
    "dict_path = Path(\"../data/external/dicionario.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88e10420-36d7-4df4-9b4c-a0d5d15f5536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Dados"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>query_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52396</th>\n",
       "      <td>1046932445034106882</td>\n",
       "      <td>É foda não tem ninguém pra conversar dia todo :(</td>\n",
       "      <td>2018-10-01 22:18:40-03:00</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65611</th>\n",
       "      <td>1046234296292380672</td>\n",
       "      <td>os amores da minha vida :(( https://t.co/nxj0Y...</td>\n",
       "      <td>2018-09-30 00:04:28-03:00</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14051</th>\n",
       "      <td>1047502185003737088</td>\n",
       "      <td>eu sou daqueles que faz um exercício de matemá...</td>\n",
       "      <td>2018-10-03 12:02:37-03:00</td>\n",
       "      <td>1</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68817</th>\n",
       "      <td>1049411245479272449</td>\n",
       "      <td>Estreia de 1ª mulher protagonista em “Doctor W...</td>\n",
       "      <td>2018-10-08 18:28:32-03:00</td>\n",
       "      <td>2</td>\n",
       "      <td>exame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45072</th>\n",
       "      <td>1047056207679299586</td>\n",
       "      <td>Gostei de um vídeo do @YouTube https://t.co/V7...</td>\n",
       "      <td>2018-10-02 06:30:27-03:00</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                                         tweet_text  \\\n",
       "52396  1046932445034106882   É foda não tem ninguém pra conversar dia todo :(   \n",
       "65611  1046234296292380672  os amores da minha vida :(( https://t.co/nxj0Y...   \n",
       "14051  1047502185003737088  eu sou daqueles que faz um exercício de matemá...   \n",
       "68817  1049411245479272449  Estreia de 1ª mulher protagonista em “Doctor W...   \n",
       "45072  1047056207679299586  Gostei de um vídeo do @YouTube https://t.co/V7...   \n",
       "\n",
       "                     tweet_date  sentiment query_used  \n",
       "52396 2018-10-01 22:18:40-03:00          0         :(  \n",
       "65611 2018-09-30 00:04:28-03:00          0         :(  \n",
       "14051 2018-10-03 12:02:37-03:00          1         :)  \n",
       "68817 2018-10-08 18:28:32-03:00          2      exame  \n",
       "45072 2018-10-02 06:30:27-03:00          0         :(  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Dicionário"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variavel</th>\n",
       "      <th>significado</th>\n",
       "      <th>tipo</th>\n",
       "      <th>valores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>ID único por usuário</td>\n",
       "      <td>useless</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tweet_text</td>\n",
       "      <td>Texto publicado</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tweet_date</td>\n",
       "      <td>Data de publicação</td>\n",
       "      <td>time</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>Algorítmo de classificação do sentimento do us...</td>\n",
       "      <td>nominal</td>\n",
       "      <td>[0,1,2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>query_used</td>\n",
       "      <td>Palavra relevante</td>\n",
       "      <td>nominal</td>\n",
       "      <td>[':)', ':(', 'veja', 'jornaloglobo', 'g1', 'fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     variavel                                        significado     tipo  \\\n",
       "0          id                               ID único por usuário  useless   \n",
       "1  tweet_text                                    Texto publicado     text   \n",
       "2  tweet_date                                 Data de publicação     time   \n",
       "3   sentiment  Algorítmo de classificação do sentimento do us...  nominal   \n",
       "4  query_used                                  Palavra relevante  nominal   \n",
       "\n",
       "                                             valores  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                            [0,1,2]  \n",
       "4  [':)', ':(', 'veja', 'jornaloglobo', 'g1', 'fo...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# leitura conjunto de dados\n",
    "df_data = pd.read_csv(data_path, sep=\";\").sample(10000)\n",
    "\n",
    "# padronização tweet_date\n",
    "df_data['tweet_date'] = pd.to_datetime(df_data['tweet_date'])\n",
    "df_data['tweet_date'] = df_data.tweet_date.dt.tz_convert('Brazil/East')\n",
    "\n",
    "# visualização dados\n",
    "display(Markdown(\"### Dados\"))\n",
    "display(df_data.head())\n",
    "\n",
    "# leitura dicionário de dados\n",
    "df_dict = pd.read_csv(dict_path)\n",
    "\n",
    "# visualização dicionário de dados\n",
    "display(Markdown(\"### Dicionário\"))\n",
    "display(df_dict.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceae3e85-6d94-410e-8df7-d1d1576db288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['useless', 'text', 'time', 'nominal'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tipos de variáveis obtidas do dicionário de dados\n",
    "df_dict.tipo.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61a58efc-41d6-40ca-810d-6fa47f97bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = \"sentiment\"\n",
    "useless_columns =  df_dict.query(\"tipo == 'useless'\").variavel.to_list()\n",
    "nominal_columns = (\n",
    "    df_dict\n",
    "    .query(\n",
    "        \"tipo == 'nominal' and \"\n",
    "        \"variavel not in @useless_columns and \"\n",
    "        \"variavel != @target_column\"\n",
    "    )\n",
    "    .variavel\n",
    "    .to_list()\n",
    ")\n",
    "text_columns = (\n",
    "    df_dict\n",
    "    .query(\n",
    "        \"tipo == 'text' and \"\n",
    "        \"variavel not in @useless_columns and \"\n",
    "        \"variavel != @target_column\"\n",
    "    )\n",
    "    .variavel\n",
    "    .to_list()\n",
    ")\n",
    "time_columns = (\n",
    "    df_dict\n",
    "    .query(\n",
    "        \"tipo == 'time' and \"\n",
    "        \"variavel not in @useless_columns and \"\n",
    "        \"variavel != @target_column\"\n",
    "    )\n",
    "    .variavel\n",
    "    .to_list()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e43ca3ca-6293-408c-836b-e05500eff727",
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_preprocessor = Pipeline([\n",
    "    # Tratamento de dados discrepantes\n",
    "    (\"missing\", SimpleImputer(strategy='most_frequent')), # Tratamento de dados faltantes\n",
    "    (\"encoder\", OneHotEncoder(sparse=False)), # Codificação de variáveis\n",
    "    # Seleção de variáveis\n",
    "    (\"normalization\", StandardScaler()) # Normalização\n",
    "])\n",
    "text_preprocessor = Pipeline([\n",
    "    (\"bag of words\", CountVectorizer(max_features=3000, stop_words=stop_words, strip_accents='ascii', \n",
    "                      lowercase=True)),\n",
    "    # Tratamento de dados faltantes\n",
    "    # Codificação de variáveis\n",
    "    # Seleção de variáveis\n",
    "     (\"normalization\", StandardScaler(with_mean=False)) # Normalização\n",
    "])\n",
    "time_preprocessor = Pipeline([\n",
    "    # Tratamento de dados discrepantes\n",
    "    # Tratamento de dados faltantes\n",
    "    (\"encoder\", OrdinalEncoder()),# Codificação de variáveis\n",
    "    # Seleção de variáveis\n",
    "    # Normalização\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "716c84be-bf32-4fb8-8d9d-8977896d3ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"nominal\", nominal_preprocessor, nominal_columns),\n",
    "    (\"text\", text_preprocessor, text_columns),\n",
    "    (\"time\", time_preprocessor, time_columns),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fa0ee72-9840-436a-b13a-a780c5bae43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_data.drop(columns=[*useless_columns, target_column], axis=1)\n",
    "y = df_data[[target_column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "420ad3b4-9948-4e7f-b133-43ae37ff9674",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joseaurelio/.cache/pypoetry/virtualenvs/src-2zHzSJE6-py3.8/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ate', 'eramos', 'estao', 'estavamos', 'estiveramos', 'estivessemos', 'foramos', 'fossemos', 'ha', 'hao', 'houveramos', 'houverao', 'houveriamos', 'houvessemos', 'ja', 'nao', 'sao', 'sera', 'serao', 'seriamos', 'so', 'tambem', 'tera', 'terao', 'teriamos', 'tinhamos', 'tiveramos', 'tivessemos', 'voce', 'voces'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 10000 and the array at index 1 has size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preprocessor\u001b[38;5;241m.\u001b[39mfit(X)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-2zHzSJE6-py3.8/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py:657\u001b[0m, in \u001b[0;36mColumnTransformer.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;124;03m\"\"\"Fit all transformers using X.\u001b[39;00m\n\u001b[1;32m    640\u001b[0m \n\u001b[1;32m    641\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;124;03m    This estimator.\u001b[39;00m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;66;03m# we use fit_transform to make sure to set sparse_output_ (for which we\u001b[39;00m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;66;03m# need the transformed data) to have consistent output type in predict\u001b[39;00m\n\u001b[0;32m--> 657\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-2zHzSJE6-py3.8/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py:714\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_output(Xs)\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_record_output_indices(Xs)\n\u001b[0;32m--> 714\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hstack\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mXs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-2zHzSJE6-py3.8/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py:806\u001b[0m, in \u001b[0;36mColumnTransformer._hstack\u001b[0;34m(self, Xs)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    805\u001b[0m     Xs \u001b[38;5;241m=\u001b[39m [f\u001b[38;5;241m.\u001b[39mtoarray() \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(f) \u001b[38;5;28;01melse\u001b[39;00m f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m Xs]\n\u001b[0;32m--> 806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-2zHzSJE6-py3.8/lib/python3.8/site-packages/numpy/core/shape_base.py:345\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 10000 and the array at index 1 has size 1"
     ]
    }
   ],
   "source": [
    "preprocessor.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dac0235-0c5d-4630-baf5-3dc4cc05bcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.transform(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
